---
title: "Turtelly Unexpected Tomfoolery"
author: "Turtles Thevenard"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    fig_width: 10
    fig_height: 6
    code_folding: hide
    theme: lumen
  pdf_document:
    latex_engine: xelatex
  word_document: default
---


<!-- 
* Configure ODK Central base URL (url), project ID (pid), and form ID (fid) 
in one step using the OData Service URL.
* Paste your own Service URL over `svc="..."`.
* Paste your local timezone over `Australia/Perth`.
* Adjust `loc` to a local subfolder for downloaded attachments.
-->
```{r setup, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(collapse = TRUE, comment = "#>")
# Data wrangling
library(dplyr)
library(fs)
library(ruODK)

# Visualisation
library(skimr)
library(knitr)
library(DT)
library(leaflet)

# Dissemination
library(readr)
# library(ckanr)
# library(googledrive)

# Spatial
# library(stringr)
# library(rgeos)
# library(sf)

# Set ruODK defaults to an ODK Central form, choose tz and verbosity
ruODK::ru_setup(
  svc=paste0("https://odkc.dbca.wa.gov.au/v1/projects/1/forms/",
             "Turtelly-Unexpected-Tomfoolery.svc"),
  odkc_version = 1.0)

loc <- fs::path("media")
fs::dir_create(loc)
```

# Download data
```{r dl_submissions}
data <- ruODK::odata_submission_get(local_dir = loc, wkt = TRUE)
```

# Analyse and visualise data
<!-- Summarise, analyse, visualise the tibble(s) data (, data_sub1, data_sub2) -->
```{r data_vis, eval=F}
skimr::skim(data)
dplyr::glimpse(data)
DT::datatable(head(data))
```

```{r data_map}
leaflet::leaflet(width = 800, height = 600) %>%
  leaflet::addProviderTiles("OpenStreetMap.Mapnik", group = "Place names") %>%
  leaflet::addProviderTiles("Esri.WorldImagery", group = "Aerial") %>%
  leaflet::clearBounds() %>%
  leaflet::addAwesomeMarkers(
    data = data,
    # 
    # # Adjust to your coordinate field names
    # 
    lng = ~details_location_longitude, 
    lat = ~details_location_latitude, 
    icon = leaflet::makeAwesomeIcon(text = "Q", markerColor = "red"),
    # 
    # # With your own field names
    # 
    label = ~ glue::glue("{encountered_on} {wastdr::humanize(details_event_type)}"),
    popup = ~ glue::glue(
      "<h3>{wastdr::humanize(details_event_type)}</h3>",
      "Seen on {encountered_on}</br>",
      "Reporter {reporter}</br>",
      "Device {device_id}</br>",
      "{details_description}<br/>",
      '<div><img src="{details_photo}"',
      ' height="150px" alt="{details_description}"></img></div>'
    ),
    clusterOptions = leaflet::markerClusterOptions()
  ) %>%
  leaflet::addLayersControl(
    baseGroups = c("Place names", "Aerial"),
    options = leaflet::layersControlOptions(collapsed = FALSE)
  )
```

# Export
<!--
The form submissions are now extracted and visualised. What's next:

* Save data to local files (e.g. CSV).
* Compile report (e.g. to HTML).
* Compress all outputs as ZIP.
* Upload these artifacts to a CKAN data catalogue.
* Upload same artifacts to Google Drive.

Notes: 

* Generate the HTML report once off without the next chunk (`eval=F`), 
as the chunk refers to the rendered output file (HTML) before the file is 
created initially.
* Run report always twice to generate (run 1) and upload (run 2) the latest HTML.
-->
```{r data_export, eval=FALSE}
#------------------------------------------------------------------------------#
# Prepare report and products as local files
#
rep_fn <- "my_report.html" # The file name you save this template under
data_fn <- here::here(loc, "data.csv") %>% as.character()           # Main data
data_sub1_fn <- here::here(loc, "data_sub1.csv") %>% as.character() # Sub table 1
data_sub2_fn <- here::here(loc, "data_sub2.csv") %>% as.character() # Sub table 2
zip_fn <- "products.zip" # Attachments as one zip file (top level)

# Write data tbls to CSV files
readr::write_csv(data, path = data_fn)
readr::write_csv(data_sub1, path = data_sub1_fn)
readr::write_csv(data_sub2, path = data_sub2_fn)

# Compress everything into `zip_fn`, retain relative path to `loc`
zip(zipfile = zip_fn, files = fs::dir_ls(loc))

#------------------------------------------------------------------------------#
# CKAN
#
# Upload to a CKAN data catalogue (need url and API key of a write permitted user)
# See ROpenSci package ckanr
ckanr::ckanr_setup(url = Sys.getenv("CKAN_URL"), key = Sys.getenv("CKAN_KEY"))
ckan_ds_name <- "my-ckan-dataset-slug"

# Run once to create resources on an existing dataset, then comment out
d <- ckanr::package_show(ckan_ds_name)
res_data_main <- ckanr::resource_create(
  package_id = d$id, name="Main data", upload = data_fn)
res_data_sub1 <- ckanr::resource_create(
  package_id = d$id, name="Nested data table 1", upload = data_sub1_fn)
res_data_sub2 <- ckanr::resource_create(
  package_id = d$id, name="Nested data table 2", upload = data_sub2_fn)
res_report <- ckanr::resource_create(
  package_id = d$id, name="Data report", upload = rep_fn)
res_zip <- ckanr::resource_create(
  package_id = d$id, name="All data and attachments", upload = zip_fn)

# Paste res_data_main$id over RID and keep here, repeat for each resource
r <- ckanr::resource_update(res_data_main$id, path = data_fn)
r <- ckanr::resource_update(res_data_sub1$id, path = data_sub1_fn)
r <- ckanr::resource_update(res_data_sub2$id, path = data_sub2_fn)
r <- ckanr::resource_update(res_report$id, path = res_report)
r <- ckanr::resource_update(res_zip$id, path = zip_fn)

#------------------------------------------------------------------------------#
# Google Drive
#
# Run once per machine, then comment out:
googledrive::drive_auth(use_oob = TRUE)

# Upload to Google Drive
gd_fn <- "My Google Drive folder name"
googledrive::drive_ls(gd_fn) %>% googledrive::drive_rm(.)  # Wipe older outputs
googledrive::drive_upload(rep_fn, path=rep_fn)             # Report as HTML
googledrive::drive_upload(data_fn, path=data_fn)           # Main data as CSV
googledrive::drive_upload(data_sub1_fn, path=data_sub1_fn) # Sub table 1 as CSV
googledrive::drive_upload(data_sub2_fn, path=data_sub2_fn) # Sub table 2 as CSV
googledrive::drive_upload(zip_fn, path=zip_fn)             # All outputs as ZIP
```
